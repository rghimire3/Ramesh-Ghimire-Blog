[
  {
    "objectID": "posts/my first post/Ghimire_Ramesh.html#business-problem",
    "href": "posts/my first post/Ghimire_Ramesh.html#business-problem",
    "title": "ADTA 5410 by Bulut",
    "section": "Business Problem",
    "text": "Business Problem\nWe’ll be exploring the 2004 North Carolina birth records. Our focus will be on examining the connection between the behaviors and routines of pregnant mothers and the outcomes of their childbirth. Please note, the dataset we’ll be using is a randomly selected subset of the original dataset.\nAttributes:\n\nPredictors\n\nfage: father’s age in years.\nmage: mother’s age in years.\nmature: maturity status of mother.\nweeks: length of pregnancy in weeks.\npremie: whether the birth was classified as premature (premie) or full-term.\nvisits: number of hospital visits during pregnancy.\nmarital: whether mother is married or not married at birth.\ngained: weight gained by mother during pregnancy in pounds.\ngender: gender of the baby, female or male.\nhabit: status of the mother as a nonsmoker or a smoker.\nwhitemom: whether mother is white or not white.\n\n\nOutcome Variable:\n\nweight: weight of the baby at birth in pounds. (Regression problem)\n\n\nDo not change anything in this r chunk. Just run the code chunk and move to the next one"
  },
  {
    "objectID": "posts/my first post/Ghimire_Ramesh.html#task-1-data-preparation",
    "href": "posts/my first post/Ghimire_Ramesh.html#task-1-data-preparation",
    "title": "ADTA 5410 by Bulut",
    "section": "Task 1: Data Preparation",
    "text": "Task 1: Data Preparation\n\n\n\n\n\n\nTask 1\n\n\n\n\nData Structure Check:\n\nExamine the variable descriptions and the overall structure of the dataset in mydata.\nEnsure that each variable is correctly coded in the R object. Specifically, numeric variables should be in numeric format, and factor variables should be coded as factors.\n\nHandling Missing Values:\n\nIdentify and replace missing values in your dataset.\n\nFor numeric variables, fill missing values with the median of that variable.\nFor categorical variables, use the most frequent category (mode) to replace missing values.\n\n\nCorrelation Analysis and Visualization:\n\nDetermine the variable that has the highest correlation (in absolute value) with your chosen target variable.\nCreate a scatter plot to visually represent the relationship between these two variables.\nProvide a brief commentary on the scatter plot. Discuss any notable patterns, trends, or insights you observe.\nInsert your written response in here:"
  },
  {
    "objectID": "posts/my first post/Ghimire_Ramesh.html#your-code-for-task-1",
    "href": "posts/my first post/Ghimire_Ramesh.html#your-code-for-task-1",
    "title": "ADTA 5410 by Bulut",
    "section": "Your code for Task 1",
    "text": "Your code for Task 1\n\nData Structure Check:\n\nExamine the variable descriptions and the overall structure of the dataset in mydata.\nEnsure that each variable is correctly coded in the R object. Specifically, numeric variables should be in numeric format, and factor variables should be coded as factors.\n\n\n\n# Display the structure of the dataset\nstr(mydata)\n\n'data.frame':   999 obs. of  12 variables:\n $ fage    : int  NA NA 19 21 NA NA 18 17 NA 20 ...\n $ mage    : int  13 14 15 15 15 15 15 15 16 16 ...\n $ mature  : chr  \"younger mom\" \"younger mom\" \"younger mom\" \"younger mom\" ...\n $ weeks   : int  39 42 37 41 39 38 37 35 38 37 ...\n $ premie  : chr  \"full term\" \"full term\" \"full term\" \"full term\" ...\n $ visits  : int  10 15 11 6 9 19 12 5 9 13 ...\n $ marital : chr  \"married\" \"married\" \"married\" \"married\" ...\n $ gained  : int  38 20 38 34 27 22 76 15 NA 52 ...\n $ weight  : num  7.63 7.88 6.63 8 6.38 5.38 8.44 4.69 8.81 6.94 ...\n $ gender  : chr  \"male\" \"male\" \"female\" \"male\" ...\n $ habit   : chr  \"nonsmoker\" \"nonsmoker\" \"nonsmoker\" \"nonsmoker\" ...\n $ whitemom: chr  \"not white\" \"not white\" \"white\" \"white\" ...\n\n\n\n# Summary statistics for numeric variables\nsummary(mydata)\n\n      fage            mage          mature              weeks      \n Min.   :14.00   Min.   :13.00   Length:999         Min.   :20.00  \n 1st Qu.:25.00   1st Qu.:22.00   Class :character   1st Qu.:37.00  \n Median :30.00   Median :27.00   Mode  :character   Median :39.00  \n Mean   :30.26   Mean   :26.99                      Mean   :38.33  \n 3rd Qu.:35.00   3rd Qu.:32.00                      3rd Qu.:40.00  \n Max.   :55.00   Max.   :50.00                      Max.   :45.00  \n NA's   :170                                        NA's   :1      \n    premie              visits       marital              gained     \n Length:999         Min.   : 0.0   Length:999         Min.   : 0.00  \n Class :character   1st Qu.:10.0   Class :character   1st Qu.:20.00  \n Mode  :character   Median :12.0   Mode  :character   Median :30.00  \n                    Mean   :12.1                      Mean   :30.33  \n                    3rd Qu.:15.0                      3rd Qu.:38.00  \n                    Max.   :30.0                      Max.   :85.00  \n                    NA's   :8                         NA's   :26     \n     weight          gender             habit             whitemom        \n Min.   : 1.000   Length:999         Length:999         Length:999        \n 1st Qu.: 6.380   Class :character   Class :character   Class :character  \n Median : 7.310   Mode  :character   Mode  :character   Mode  :character  \n Mean   : 7.104                                                           \n 3rd Qu.: 8.060                                                           \n Max.   :11.750                                                           \n                                                                          \n\n\n\n# Check class/type of each variable\nsapply(mydata, class)\n\n       fage        mage      mature       weeks      premie      visits \n  \"integer\"   \"integer\" \"character\"   \"integer\" \"character\"   \"integer\" \n    marital      gained      weight      gender       habit    whitemom \n\"character\"   \"integer\"   \"numeric\" \"character\" \"character\" \"character\" \n\n\n\n# Check factor levels for factor variables\nsapply(mydata, function(x) if(is.factor(x)) levels(x))\n\n$fage\nNULL\n\n$mage\nNULL\n\n$mature\nNULL\n\n$weeks\nNULL\n\n$premie\nNULL\n\n$visits\nNULL\n\n$marital\nNULL\n\n$gained\nNULL\n\n$weight\nNULL\n\n$gender\nNULL\n\n$habit\nNULL\n\n$whitemom\nNULL\n\n\n\n# Recode variables as needed\nmydata$mature &lt;- as.factor(mydata$mature)\nmydata$premie &lt;- as.factor(mydata$premie) \n\n\n# Confirm classes after recoding\nsapply(mydata, class)\n\n       fage        mage      mature       weeks      premie      visits \n  \"integer\"   \"integer\"    \"factor\"   \"integer\"    \"factor\"   \"integer\" \n    marital      gained      weight      gender       habit    whitemom \n\"character\"   \"integer\"   \"numeric\" \"character\" \"character\" \"character\" \n\n\n\nHandling Missing Values:\n\nIdentify and replace missing values in your dataset.\n\nFor numeric variables, fill missing values with the median of that variable.\nFor categorical variables, use the most frequent category (mode) to replace missing values.\n\n\n\n\nlibrary(dplyr)\nlibrary(tidyr)\n\n# Identify missing values\nsapply(mydata, function(x) sum(is.na(x)))\n\n    fage     mage   mature    weeks   premie   visits  marital   gained \n     170        0        0        1        1        8        0       26 \n  weight   gender    habit whitemom \n       0        0        0        2 \n\n\n\n# Numeric variables - fill with median\nnum_vars &lt;- c(\"fage\", \"mage\", \"weeks\", \"visits\", \"gained\", \"weight\")\nfor(v in num_vars) {\n  med &lt;- median(mydata[[v]], na.rm = TRUE) \n  mydata[[v]][is.na(mydata[[v]])] &lt;- med\n}\n\n\n# Categorical variables - fill with mode \ncat_vars &lt;- c(\"mature\", \"premie\", \"marital\", \"gender\", \"habit\", \"whitemom\")\nfor(v in cat_vars) {\n  mod &lt;- names(which.max(table(mydata[[v]])))\n  mydata[[v]][is.na(mydata[[v]])] &lt;- mod  \n}\n\n\n# Check if any NAs remain\nsapply(mydata, function(x) sum(is.na(x)))\n\n    fage     mage   mature    weeks   premie   visits  marital   gained \n       0        0        0        0        0        0        0        0 \n  weight   gender    habit whitemom \n       0        0        0        0 \n\n\nCorrelation Analysis and Visualization:\n\nDetermine the variable that has the highest correlation (in absolute value) with your chosen target variable.\nCreate a scatter plot to visually represent the relationship between these two variables.\nProvide a brief commentary on the scatter plot. Discuss any notable patterns, trends, or insights you observe.\n\n\n# Determine variable with highest correlation\ncor_mat &lt;- cor(mydata[sapply(mydata, is.numeric)], use=\"pairwise.complete.obs\")\nhighest_cor &lt;- which.max(abs(cor_mat[\"weight\",]))\nnames(highest_cor) \n\n[1] \"weight\"\n\n# Plot scatterplot \ntarget_var &lt;- \"weight\"\npred_var &lt;- names(highest_cor)\n\nggplot(mydata, aes_string(x = pred_var, y = target_var)) + \n  geom_point(alpha = 0.5) +\n  ggtitle(paste0(\"Scatterplot of \", target_var, \" vs \", pred_var))\n\nWarning: `aes_string()` was deprecated in ggplot2 3.0.0.\nℹ Please use tidy evaluation idioms with `aes()`.\nℹ See also `vignette(\"ggplot2-in-packages\")` for more information.\n\n\n\n\n\nWeight gained exhibits the highest absolute correlation with birth weight. The graph illustrates a positive correlation, indicating that mothers who gained extra weight during pregnancy tended to have babies with higher weights. Although there are a few outliers, the general trend suggests that weight gain during pregnancy supports fetal development."
  },
  {
    "objectID": "posts/my first post/Ghimire_Ramesh.html#task-2-data-splitting",
    "href": "posts/my first post/Ghimire_Ramesh.html#task-2-data-splitting",
    "title": "ADTA 5410 by Bulut",
    "section": "Task 2: Data Splitting",
    "text": "Task 2: Data Splitting\n\n\n\n\n\n\n\nTask 2\n\n\n\n\nPrior to starting our analysis, we will divide our dataset into two parts: a training set and a test set. For this lab assignment, you’ll need to use the initial_split function from the rsample package in R to partition the data. Please ensure to use set.seed(123456) for reproducibility. Allocate 70% of the data to the training set and go with the default options in initial_split function. Conduct stratified sampling by using strata=\"weight\".\nName your training set train_data and your test set test_data. This division will be crucial for our analysis, allowing us to train our models effectively and test their performance."
  },
  {
    "objectID": "posts/my first post/Ghimire_Ramesh.html#your-code-for-task-2",
    "href": "posts/my first post/Ghimire_Ramesh.html#your-code-for-task-2",
    "title": "ADTA 5410 by Bulut",
    "section": "Your code for Task 2",
    "text": "Your code for Task 2\n\n# Please provide your code for Task 2 in this code chunk\n# split the sample by using rsample package\n\n# Split the data into a training set (70%) and a test set (30%)\nset.seed(123456)\n\n# Load rsample package\nlibrary(rsample)\n\n# Take a 70/30 split stratified on weight \nsplit &lt;- initial_split(mydata, prop = 0.7, strata = \"weight\")\n\n# Extract training and test sets\ntrain_data &lt;- training(split) \ntest_data &lt;- testing(split)\n\n# Check proportions\nprop.table(table(train_data$weight)) \n\n\n          1        1.19        1.31        1.38        1.44         1.5 \n0.001432665 0.001432665 0.001432665 0.002865330 0.001432665 0.002865330 \n       1.56        1.69        2.25         2.5        2.63        2.69 \n0.001432665 0.002865330 0.001432665 0.001432665 0.001432665 0.001432665 \n       2.88        2.94           3        3.19        3.25        3.31 \n0.004297994 0.001432665 0.001432665 0.001432665 0.001432665 0.001432665 \n       3.56        3.63        3.75        3.81        3.94           4 \n0.001432665 0.001432665 0.002865330 0.001432665 0.001432665 0.001432665 \n       4.06        4.13        4.19        4.25        4.31        4.44 \n0.002865330 0.002865330 0.001432665 0.001432665 0.001432665 0.004297994 \n        4.5        4.56        4.63        4.69        4.75        4.88 \n0.002865330 0.002865330 0.002865330 0.005730659 0.007163324 0.001432665 \n       4.94           5        5.06        5.13        5.19        5.25 \n0.001432665 0.002865330 0.002865330 0.002865330 0.001432665 0.004297994 \n       5.38        5.44         5.5        5.56        5.63        5.69 \n0.010028653 0.007163324 0.008595989 0.002865330 0.008595989 0.004297994 \n       5.75        5.81        5.88        5.94           6        6.06 \n0.004297994 0.007163324 0.007163324 0.017191977 0.014326648 0.008595989 \n       6.13        6.19        6.25        6.31        6.38        6.44 \n0.005730659 0.011461318 0.011461318 0.014326648 0.017191977 0.005730659 \n        6.5        6.56        6.63        6.69        6.75        6.81 \n0.015759312 0.015759312 0.010028653 0.008595989 0.020057307 0.012893983 \n       6.88        6.94           7        7.06        7.13        7.19 \n0.021489971 0.017191977 0.022922636 0.020057307 0.018624642 0.021489971 \n       7.25        7.31        7.38        7.44         7.5        7.56 \n0.024355301 0.030085960 0.022922636 0.031518625 0.022922636 0.024355301 \n       7.63        7.69        7.75        7.81        7.88        7.94 \n0.014326648 0.015759312 0.015759312 0.021489971 0.027220630 0.014326648 \n          8        8.06        8.13        8.19        8.25        8.31 \n0.018624642 0.010028653 0.020057307 0.020057307 0.020057307 0.012893983 \n       8.38        8.44         8.5        8.56        8.63        8.69 \n0.021489971 0.007163324 0.015759312 0.011461318 0.005730659 0.005730659 \n       8.75        8.81        8.88        8.94           9        9.06 \n0.010028653 0.011461318 0.010028653 0.005730659 0.007163324 0.005730659 \n       9.13        9.19        9.25        9.31        9.38         9.5 \n0.007163324 0.007163324 0.004297994 0.002865330 0.001432665 0.002865330 \n       9.56        9.63        9.75        9.81        9.88        9.94 \n0.004297994 0.002865330 0.001432665 0.001432665 0.004297994 0.001432665 \n      10.06       10.13       10.19       10.25       11.75 \n0.001432665 0.001432665 0.001432665 0.001432665 0.001432665 \n\nprop.table(table(test_data$weight))\n\n\n          1        1.38        1.44        1.63        1.88        2.19 \n0.003322259 0.003322259 0.003322259 0.003322259 0.003322259 0.003322259 \n       2.25        2.69        3.44        3.94           4         4.5 \n0.003322259 0.003322259 0.003322259 0.003322259 0.003322259 0.003322259 \n       4.56        4.75        4.94           5        5.06        5.19 \n0.006644518 0.003322259 0.003322259 0.006644518 0.003322259 0.003322259 \n       5.25        5.38        5.44         5.5        5.56        5.63 \n0.003322259 0.003322259 0.006644518 0.003322259 0.009966777 0.006644518 \n       5.69        5.75        5.81        5.88        5.94           6 \n0.003322259 0.003322259 0.013289037 0.023255814 0.009966777 0.016611296 \n       6.06        6.13        6.19        6.25        6.31        6.38 \n0.013289037 0.006644518 0.009966777 0.026578073 0.016611296 0.013289037 \n       6.44         6.5        6.56        6.63        6.69        6.75 \n0.013289037 0.013289037 0.006644518 0.006644518 0.023255814 0.029900332 \n       6.81        6.88        6.94           7        7.06        7.13 \n0.009966777 0.033222591 0.006644518 0.019933555 0.019933555 0.036544850 \n       7.19        7.25        7.31        7.38        7.44         7.5 \n0.019933555 0.016611296 0.009966777 0.016611296 0.026578073 0.026578073 \n       7.56        7.63        7.69        7.75        7.81        7.88 \n0.006644518 0.026578073 0.019933555 0.019933555 0.016611296 0.019933555 \n       7.94           8        8.06        8.13        8.19        8.25 \n0.019933555 0.019933555 0.019933555 0.009966777 0.009966777 0.006644518 \n       8.31        8.38        8.44         8.5        8.56        8.63 \n0.009966777 0.016611296 0.029900332 0.013289037 0.009966777 0.003322259 \n       8.75        8.81        8.88           9        9.06        9.13 \n0.023255814 0.013289037 0.006644518 0.009966777 0.006644518 0.006644518 \n       9.19        9.25        9.31        9.38         9.5        9.63 \n0.006644518 0.009966777 0.009966777 0.003322259 0.006644518 0.003322259 \n       9.69        9.75        9.88       10.06       10.13       10.38 \n0.003322259 0.003322259 0.003322259 0.003322259 0.003322259 0.003322259 \n      11.63 \n0.003322259 \n\n\n\nsplit &lt;- initial_split(mydata, prop = 0.7, strata = \"weight\")\n\ntrain_data &lt;- training(split)\ntest_data &lt;- testing(split)"
  },
  {
    "objectID": "posts/my first post/Ghimire_Ramesh.html#task-3",
    "href": "posts/my first post/Ghimire_Ramesh.html#task-3",
    "title": "ADTA 5410 by Bulut",
    "section": "Task 3:",
    "text": "Task 3:\n\n\n\n\n\n\nTask 3\n\n\n\n\nIn this task, you will be using the train_data dataset to run a linear regression that takes weight as the dependent variable and all the other columns as the predictor.\n\nYou will use the lm() function to estimate your linear model and name it as linearmodel.\nUse the predict() function to predict the weight variable in the test_data dataset using linearmodel.\nStore the resulting predictions in a new object called predicted_weights_ols.\nCalculate the mean squared prediction error in the test_data dataset by comparing the predicted weight values with the actual weight values. Store the resulting value in an object called MSPE_linear.\n\nNeed Written Response: Print the value of MSPE_linear to the console using the print() function"
  },
  {
    "objectID": "posts/my first post/Ghimire_Ramesh.html#your-code-for-task-3",
    "href": "posts/my first post/Ghimire_Ramesh.html#your-code-for-task-3",
    "title": "ADTA 5410 by Bulut",
    "section": "Your code for Task 3",
    "text": "Your code for Task 3\n\n# Please provide your code for Task 3  in this code chunk\n\n\n# Linear model on training data \nlinearmodel &lt;- lm(weight ~ ., data = train_data)\n\n# Make predictions on test data\npredicted_weights_ols &lt;- predict(linearmodel, newdata = test_data)\n\n# Calculate MSPE\nMSPE_linear &lt;- mean((test_data$weight - predicted_weights_ols)^2)\n\n# Print MSPE\nprint(MSPE_linear)\n\n[1] 1.260889\n\n\nMSPE_linear = 1.2600889, indicates improved predictions on the unseen test dataset, affirming the efficacy of the model trained on the training dataset."
  },
  {
    "objectID": "posts/my first post/Ghimire_Ramesh.html#task-4",
    "href": "posts/my first post/Ghimire_Ramesh.html#task-4",
    "title": "ADTA 5410 by Bulut",
    "section": "Task 4:",
    "text": "Task 4:\n\n\n\n\n\n\nTask 4\n\n\n\n\nUse the gam function in the mgcv package to complete the same task. In other words, fit a Generalized additive model (GAM) on the train_data using the gam() function. Use the s() function for each suitable predictor. Save your R object as gam_model. If the gam output indicates that a variable should be added linearly to the model, then make the necessary changes in gam_model and explain your reasoning. As for the parameter tuning, let the package automatically selects the optimal lambda by using the method = “REML”.\nPrint out smoothing parameter from gam_model.\nUse the predict() function to predict the weight variable in the test_data dataset using gam_model. Store the resulting predictions in a new object called predicted_weights_gam.\nCalculate the mean squared prediction error in the test_data dataset by comparing the predicted ‘weight’ values with the actual weight values. Store the resulting value in an object called MSPE_gam.\n\nPrint the value of MSPE_gam to the console using the print() function."
  },
  {
    "objectID": "posts/my first post/Ghimire_Ramesh.html#your-code-for-task-4",
    "href": "posts/my first post/Ghimire_Ramesh.html#your-code-for-task-4",
    "title": "ADTA 5410 by Bulut",
    "section": "Your code for Task 4",
    "text": "Your code for Task 4\n\n# Please provide your code for Task 4 in this code chunk\n\nlibrary(mgcv)\n\n# Fit GAM model\ngam_model &lt;- gam(weight ~ s(fage) + s(mage) + s(weeks) + s(visits) + \n                  s(gained) + marital + gender + habit + whitemom, \n                data = train_data,\n                method = \"REML\")\n\n# Print smoothing parameters\nprint(summary(gam_model)$s.table)\n\n               edf   Ref.df            F     p-value\ns(fage)   1.001200 1.002396   2.08619167 0.148759470\ns(mage)   1.000388 1.000774   0.07901458 0.779096353\ns(weeks)  5.082104 6.147774 129.50469918 0.000000000\ns(visits) 3.119598 3.963131   1.66230248 0.132546087\ns(gained) 1.000384 1.000768   6.82021548 0.009196795\n\n\n\n# Make predictions on test set\npredicted_weights_gam &lt;- predict(gam_model, newdata = test_data)\n\n# Calculate MSPE \nMSPE_gam &lt;- mean((test_data$weight - predicted_weights_gam)^2)\n\n# Print MSPE\nprint(MSPE_gam)\n\n[1] 1.16755\n\n\nMSPE_gam = 1.16755, reflects lower error and improved predictions in the GAM model, attributed to the incorporation of non-linear smoothing functions for continuous predictors."
  },
  {
    "objectID": "posts/my first post/Ghimire_Ramesh.html#task-5",
    "href": "posts/my first post/Ghimire_Ramesh.html#task-5",
    "title": "ADTA 5410 by Bulut",
    "section": "TASK 5:",
    "text": "TASK 5:\n\n\n\n\n\n\nTask 5\n\n\n\n\nEvaluate the effectiveness of the linear regression model (linearmodel) and the generalized additive model (gam_model) by comparing their Mean Squared Prediction Errors (MSPE). Utilize the values MSPE_linear and MSPE_gam, which were derived in previous tasks, to assess which model more accurately predicts the ‘weight’ variable in the test_data dataset. The model with the lower MSPE value will be considered as having superior predictive performance for this specific variable.\nInsert your written response in here:"
  },
  {
    "objectID": "posts/my first post/Ghimire_Ramesh.html#your-code-for-task-5",
    "href": "posts/my first post/Ghimire_Ramesh.html#your-code-for-task-5",
    "title": "ADTA 5410 by Bulut",
    "section": "Your code for Task 5",
    "text": "Your code for Task 5\n\n# Linear Regression MSPE: MSPE_linear = 1.260889\n\n# GAM Model MSPE: MSPE_gam = 1.16755\n\nLinear Regression MSPE: 1.260889\nGAM Model MSPE: 1.16755\nA lower MSPE signifies enhanced predictive accuracy for the ‘weight’ variable in the test dataset. In this comparison:\n\nIf MSPE_linear &lt; MSPE_gam: Linear regression outperforms in predictive performance.\nIf MSPE_gam &lt; MSPE_linear: The generalized additive model excels in predictive performance.\nIf MSPE_linear ≈ MSPE_gam: Both models perform similarly in predicting the ‘weight’ variable.\n\nAnalysis reveals the GAM model’s superiority with a lower MSPE of 1.117023, indicating reduced deviation between actual and predicted values."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Ramesh Ghimire",
    "section": "",
    "text": "Hello and good morning all,\nI am Ramesh Ghimire. As a Sr. Business Intelligence Engineer at H-E-B, I support the data and analytics needs of various business units, such as marketing, finance, and operations. I use SQL, Python, AWS Databricks, and Salesforce to design, develop, and deliver robust and scalable data solutions that enable data-driven decision making and optimize business performance. I also collaborate with cross-functional teams to provide data visualization and reporting using Tableau, MicroStrategy, and Confluence.\n\nI am passionate about learning new technologies and applying analytics to solve complex business challenges. I am currently pursuing a PhD in Data Science at University of North Texas, where I am researching advanced data analytics methods and techniques. I have a Master of Science degree in Advanced Data Analytics - Data Science from the same university. I have also earned multiple certifications in Big Data, Machine Learning, GIS, and Tableau. I have over 10 years of experience in data and BI roles, working with diverse industries and domains, such as financial services, oil and gas, and retail. I am a team player, a problem solver, and a lifelong learner."
  },
  {
    "objectID": "posts/my first post/index.html",
    "href": "posts/my first post/index.html",
    "title": "Linear regression",
    "section": "",
    "text": "Hi, Lets run a code"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome to my Blog",
    "section": "",
    "text": "Hi, my name is Ramesh Ghimire.."
  },
  {
    "objectID": "posts/my first post/subset selection/Ghimire_Ramesh.html#business-problem",
    "href": "posts/my first post/subset selection/Ghimire_Ramesh.html#business-problem",
    "title": "ADTA 5410 by Bulut",
    "section": "Business Problem",
    "text": "Business Problem\nFor this week’s homework, we’ll be exploring the 2004 North Carolina birth records. Our focus will be on examining the connection between the behaviors and routines of pregnant mothers and the outcomes of their childbirth. Please note, the dataset we’ll be using is a randomly selected subset of the original dataset.\nAttributes:\n\nPredictors\n\nfage: father’s age in years.\nmage: mother’s age in years.\nmature: maturity status of mother.\nweeks: length of pregnancy in weeks.\npremie: whether the birth was classified as premature (premie) or full-term.\nvisits: number of hospital visits during pregnancy.\nmarital: whether mother is married or not married at birth.\ngained: weight gained by mother during pregnancy in pounds.\ngender: gender of the baby, female or male.\nhabit: status of the mother as a nonsmoker or a smoker.\nwhitemom: whether mother is white or not white.\n\n\nOutcome Variable:\n\nweight: weight of the baby at birth in pounds. (Regression problem)\n\n\nDo not change anything in this r chunk. Just run the code chunk and move to the next one"
  },
  {
    "objectID": "posts/my first post/subset selection/Ghimire_Ramesh.html#task-1-data-preparation",
    "href": "posts/my first post/subset selection/Ghimire_Ramesh.html#task-1-data-preparation",
    "title": "ADTA 5410 by Bulut",
    "section": "Task 1: Data Preparation",
    "text": "Task 1: Data Preparation\n\n\n\n\n\n\nTask 1\n\n\n\n\nData Structure Check:\n\nExamine the variable descriptions and the overall structure of the dataset in mydata.\nEnsure that each variable is correctly coded in the R object. Specifically, numeric variables should be in numeric format, and factor variables should be coded as factors.\n\nHandling Missing Values:\n\nIdentify and replace missing values in your dataset.\n\nFor numeric variables, fill missing values with the median of that variable.\nFor categorical variables, use the most frequent category (mode) to replace missing values.\n\n\nCorrelation Analysis and Visualization:\n\nDetermine the variable that has the highest correlation (in absolute value) with your chosen target variable.\nCreate a scatter plot to visually represent the relationship between these two variables.\nProvide a brief commentary on the scatter plot. Discuss any notable patterns, trends, or insights you observe.\nInsert your written response in here:"
  },
  {
    "objectID": "posts/my first post/subset selection/Ghimire_Ramesh.html#your-code-for-task-1",
    "href": "posts/my first post/subset selection/Ghimire_Ramesh.html#your-code-for-task-1",
    "title": "ADTA 5410 by Bulut",
    "section": "Your code for Task 1",
    "text": "Your code for Task 1\n\nData Structure Check:\n\nExamine the variable descriptions and the overall structure of the dataset in mydata.\nEnsure that each variable is correctly coded in the R object. Specifically, numeric variables should be in numeric format, and factor variables should be coded as factors.\n\n\n\n# Display the structure of the dataset\nstr(mydata)\n\n'data.frame':   999 obs. of  12 variables:\n $ fage    : int  NA NA 19 21 NA NA 18 17 NA 20 ...\n $ mage    : int  13 14 15 15 15 15 15 15 16 16 ...\n $ mature  : chr  \"younger mom\" \"younger mom\" \"younger mom\" \"younger mom\" ...\n $ weeks   : int  39 42 37 41 39 38 37 35 38 37 ...\n $ premie  : chr  \"full term\" \"full term\" \"full term\" \"full term\" ...\n $ visits  : int  10 15 11 6 9 19 12 5 9 13 ...\n $ marital : chr  \"married\" \"married\" \"married\" \"married\" ...\n $ gained  : int  38 20 38 34 27 22 76 15 NA 52 ...\n $ weight  : num  7.63 7.88 6.63 8 6.38 5.38 8.44 4.69 8.81 6.94 ...\n $ gender  : chr  \"male\" \"male\" \"female\" \"male\" ...\n $ habit   : chr  \"nonsmoker\" \"nonsmoker\" \"nonsmoker\" \"nonsmoker\" ...\n $ whitemom: chr  \"not white\" \"not white\" \"white\" \"white\" ...\n\n\n\n# Summary statistics for numeric variables\nsummary(mydata)\n\n      fage            mage          mature              weeks      \n Min.   :14.00   Min.   :13.00   Length:999         Min.   :20.00  \n 1st Qu.:25.00   1st Qu.:22.00   Class :character   1st Qu.:37.00  \n Median :30.00   Median :27.00   Mode  :character   Median :39.00  \n Mean   :30.26   Mean   :26.99                      Mean   :38.33  \n 3rd Qu.:35.00   3rd Qu.:32.00                      3rd Qu.:40.00  \n Max.   :55.00   Max.   :50.00                      Max.   :45.00  \n NA's   :170                                        NA's   :1      \n    premie              visits       marital              gained     \n Length:999         Min.   : 0.0   Length:999         Min.   : 0.00  \n Class :character   1st Qu.:10.0   Class :character   1st Qu.:20.00  \n Mode  :character   Median :12.0   Mode  :character   Median :30.00  \n                    Mean   :12.1                      Mean   :30.33  \n                    3rd Qu.:15.0                      3rd Qu.:38.00  \n                    Max.   :30.0                      Max.   :85.00  \n                    NA's   :8                         NA's   :26     \n     weight          gender             habit             whitemom        \n Min.   : 1.000   Length:999         Length:999         Length:999        \n 1st Qu.: 6.380   Class :character   Class :character   Class :character  \n Median : 7.310   Mode  :character   Mode  :character   Mode  :character  \n Mean   : 7.104                                                           \n 3rd Qu.: 8.060                                                           \n Max.   :11.750                                                           \n                                                                          \n\n\n\n# Check class/type of each variable\nsapply(mydata, class)\n\n       fage        mage      mature       weeks      premie      visits \n  \"integer\"   \"integer\" \"character\"   \"integer\" \"character\"   \"integer\" \n    marital      gained      weight      gender       habit    whitemom \n\"character\"   \"integer\"   \"numeric\" \"character\" \"character\" \"character\" \n\n\n\n# Check factor levels for factor variables\nsapply(mydata, function(x) if(is.factor(x)) levels(x))\n\n$fage\nNULL\n\n$mage\nNULL\n\n$mature\nNULL\n\n$weeks\nNULL\n\n$premie\nNULL\n\n$visits\nNULL\n\n$marital\nNULL\n\n$gained\nNULL\n\n$weight\nNULL\n\n$gender\nNULL\n\n$habit\nNULL\n\n$whitemom\nNULL\n\n\n\n# Recode variables as needed\nmydata$mature &lt;- as.factor(mydata$mature)\nmydata$premie &lt;- as.factor(mydata$premie) \n\n\n# Confirm classes after recoding\nsapply(mydata, class)\n\n       fage        mage      mature       weeks      premie      visits \n  \"integer\"   \"integer\"    \"factor\"   \"integer\"    \"factor\"   \"integer\" \n    marital      gained      weight      gender       habit    whitemom \n\"character\"   \"integer\"   \"numeric\" \"character\" \"character\" \"character\" \n\n\n\nHandling Missing Values:\n\nIdentify and replace missing values in your dataset.\n\nFor numeric variables, fill missing values with the median of that variable.\nFor categorical variables, use the most frequent category (mode) to replace missing values.\n\n\n\n\nlibrary(dplyr)\nlibrary(tidyr)\n\n# Identify missing values\nsapply(mydata, function(x) sum(is.na(x)))\n\n    fage     mage   mature    weeks   premie   visits  marital   gained \n     170        0        0        1        1        8        0       26 \n  weight   gender    habit whitemom \n       0        0        0        2 \n\n\n\n# Numeric variables - fill with median\nnum_vars &lt;- c(\"fage\", \"mage\", \"weeks\", \"visits\", \"gained\", \"weight\")\nfor(v in num_vars) {\n  med &lt;- median(mydata[[v]], na.rm = TRUE) \n  mydata[[v]][is.na(mydata[[v]])] &lt;- med\n}\n\n\n# Categorical variables - fill with mode \ncat_vars &lt;- c(\"mature\", \"premie\", \"marital\", \"gender\", \"habit\", \"whitemom\")\nfor(v in cat_vars) {\n  mod &lt;- names(which.max(table(mydata[[v]])))\n  mydata[[v]][is.na(mydata[[v]])] &lt;- mod  \n}\n\n\n# Check if any NAs remain\nsapply(mydata, function(x) sum(is.na(x)))\n\n    fage     mage   mature    weeks   premie   visits  marital   gained \n       0        0        0        0        0        0        0        0 \n  weight   gender    habit whitemom \n       0        0        0        0 \n\n\nCorrelation Analysis and Visualization:\n\nDetermine the variable that has the highest correlation (in absolute value) with your chosen target variable.\nCreate a scatter plot to visually represent the relationship between these two variables.\nProvide a brief commentary on the scatter plot. Discuss any notable patterns, trends, or insights you observe.\n\n\n# Determine variable with highest correlation\ncor_mat &lt;- cor(mydata[sapply(mydata, is.numeric)], use=\"pairwise.complete.obs\")\nhighest_cor &lt;- which.max(abs(cor_mat[\"weight\",]))\nnames(highest_cor) \n\n[1] \"weight\"\n\n# Plot scatterplot \ntarget_var &lt;- \"weight\"\npred_var &lt;- names(highest_cor)\n\nggplot(mydata, aes_string(x = pred_var, y = target_var)) + \n  geom_point(alpha = 0.5) +\n  ggtitle(paste0(\"Scatterplot of \", target_var, \" vs \", pred_var))\n\nWarning: `aes_string()` was deprecated in ggplot2 3.0.0.\nℹ Please use tidy evaluation idioms with `aes()`.\nℹ See also `vignette(\"ggplot2-in-packages\")` for more information.\n\n\n\n\n\nWeight gained exhibits the highest absolute correlation with birth weight. The graph illustrates a positive correlation, indicating that mothers who gained extra weight during pregnancy tended to have babies with higher weights. Although there are a few outliers, the general trend suggests that weight gain during pregnancy supports fetal development."
  },
  {
    "objectID": "posts/my first post/subset selection/Ghimire_Ramesh.html#task-2-data-splitting",
    "href": "posts/my first post/subset selection/Ghimire_Ramesh.html#task-2-data-splitting",
    "title": "ADTA 5410 by Bulut",
    "section": "Task 2: Data Splitting",
    "text": "Task 2: Data Splitting\n\n\n\n\n\n\n\nTask 2\n\n\n\n\nPrior to starting our analysis, we will divide our dataset into two parts: a training set and a test set. For this lab assignment, you’ll need to use the initial_split function from the rsample package in R to partition the data. Please ensure to use set.seed(123456) for reproducibility. Allocate 70% of the data to the training set and go with the default options in initial_split function. Conduct stratified sampling by using strata=\"weight\".\nName your training set train_data and your test set test_data. This division will be crucial for our analysis, allowing us to train our models effectively and test their performance."
  },
  {
    "objectID": "posts/my first post/subset selection/Ghimire_Ramesh.html#your-code-for-task-2",
    "href": "posts/my first post/subset selection/Ghimire_Ramesh.html#your-code-for-task-2",
    "title": "ADTA 5410 by Bulut",
    "section": "Your code for Task 2",
    "text": "Your code for Task 2\n\n# Please provide your code for Task 2 in this code chunk\n# split the sample by using rsample package\n\n# Split the data into a training set (70%) and a test set (30%)\nset.seed(123456)\n\n# Load rsample package\nlibrary(rsample)\n\n# Take a 70/30 split stratified on weight \nsplit &lt;- initial_split(mydata, prop = 0.7, strata = \"weight\")\n\n# Extract training and test sets\ntrain_data &lt;- training(split) \ntest_data &lt;- testing(split)\n\n# Check proportions\nprop.table(table(train_data$weight)) \n\n\n          1        1.19        1.31        1.38        1.44         1.5 \n0.001432665 0.001432665 0.001432665 0.002865330 0.001432665 0.002865330 \n       1.56        1.69        2.25         2.5        2.63        2.69 \n0.001432665 0.002865330 0.001432665 0.001432665 0.001432665 0.001432665 \n       2.88        2.94           3        3.19        3.25        3.31 \n0.004297994 0.001432665 0.001432665 0.001432665 0.001432665 0.001432665 \n       3.56        3.63        3.75        3.81        3.94           4 \n0.001432665 0.001432665 0.002865330 0.001432665 0.001432665 0.001432665 \n       4.06        4.13        4.19        4.25        4.31        4.44 \n0.002865330 0.002865330 0.001432665 0.001432665 0.001432665 0.004297994 \n        4.5        4.56        4.63        4.69        4.75        4.88 \n0.002865330 0.002865330 0.002865330 0.005730659 0.007163324 0.001432665 \n       4.94           5        5.06        5.13        5.19        5.25 \n0.001432665 0.002865330 0.002865330 0.002865330 0.001432665 0.004297994 \n       5.38        5.44         5.5        5.56        5.63        5.69 \n0.010028653 0.007163324 0.008595989 0.002865330 0.008595989 0.004297994 \n       5.75        5.81        5.88        5.94           6        6.06 \n0.004297994 0.007163324 0.007163324 0.017191977 0.014326648 0.008595989 \n       6.13        6.19        6.25        6.31        6.38        6.44 \n0.005730659 0.011461318 0.011461318 0.014326648 0.017191977 0.005730659 \n        6.5        6.56        6.63        6.69        6.75        6.81 \n0.015759312 0.015759312 0.010028653 0.008595989 0.020057307 0.012893983 \n       6.88        6.94           7        7.06        7.13        7.19 \n0.021489971 0.017191977 0.022922636 0.020057307 0.018624642 0.021489971 \n       7.25        7.31        7.38        7.44         7.5        7.56 \n0.024355301 0.030085960 0.022922636 0.031518625 0.022922636 0.024355301 \n       7.63        7.69        7.75        7.81        7.88        7.94 \n0.014326648 0.015759312 0.015759312 0.021489971 0.027220630 0.014326648 \n          8        8.06        8.13        8.19        8.25        8.31 \n0.018624642 0.010028653 0.020057307 0.020057307 0.020057307 0.012893983 \n       8.38        8.44         8.5        8.56        8.63        8.69 \n0.021489971 0.007163324 0.015759312 0.011461318 0.005730659 0.005730659 \n       8.75        8.81        8.88        8.94           9        9.06 \n0.010028653 0.011461318 0.010028653 0.005730659 0.007163324 0.005730659 \n       9.13        9.19        9.25        9.31        9.38         9.5 \n0.007163324 0.007163324 0.004297994 0.002865330 0.001432665 0.002865330 \n       9.56        9.63        9.75        9.81        9.88        9.94 \n0.004297994 0.002865330 0.001432665 0.001432665 0.004297994 0.001432665 \n      10.06       10.13       10.19       10.25       11.75 \n0.001432665 0.001432665 0.001432665 0.001432665 0.001432665 \n\nprop.table(table(test_data$weight))\n\n\n          1        1.38        1.44        1.63        1.88        2.19 \n0.003322259 0.003322259 0.003322259 0.003322259 0.003322259 0.003322259 \n       2.25        2.69        3.44        3.94           4         4.5 \n0.003322259 0.003322259 0.003322259 0.003322259 0.003322259 0.003322259 \n       4.56        4.75        4.94           5        5.06        5.19 \n0.006644518 0.003322259 0.003322259 0.006644518 0.003322259 0.003322259 \n       5.25        5.38        5.44         5.5        5.56        5.63 \n0.003322259 0.003322259 0.006644518 0.003322259 0.009966777 0.006644518 \n       5.69        5.75        5.81        5.88        5.94           6 \n0.003322259 0.003322259 0.013289037 0.023255814 0.009966777 0.016611296 \n       6.06        6.13        6.19        6.25        6.31        6.38 \n0.013289037 0.006644518 0.009966777 0.026578073 0.016611296 0.013289037 \n       6.44         6.5        6.56        6.63        6.69        6.75 \n0.013289037 0.013289037 0.006644518 0.006644518 0.023255814 0.029900332 \n       6.81        6.88        6.94           7        7.06        7.13 \n0.009966777 0.033222591 0.006644518 0.019933555 0.019933555 0.036544850 \n       7.19        7.25        7.31        7.38        7.44         7.5 \n0.019933555 0.016611296 0.009966777 0.016611296 0.026578073 0.026578073 \n       7.56        7.63        7.69        7.75        7.81        7.88 \n0.006644518 0.026578073 0.019933555 0.019933555 0.016611296 0.019933555 \n       7.94           8        8.06        8.13        8.19        8.25 \n0.019933555 0.019933555 0.019933555 0.009966777 0.009966777 0.006644518 \n       8.31        8.38        8.44         8.5        8.56        8.63 \n0.009966777 0.016611296 0.029900332 0.013289037 0.009966777 0.003322259 \n       8.75        8.81        8.88           9        9.06        9.13 \n0.023255814 0.013289037 0.006644518 0.009966777 0.006644518 0.006644518 \n       9.19        9.25        9.31        9.38         9.5        9.63 \n0.006644518 0.009966777 0.009966777 0.003322259 0.006644518 0.003322259 \n       9.69        9.75        9.88       10.06       10.13       10.38 \n0.003322259 0.003322259 0.003322259 0.003322259 0.003322259 0.003322259 \n      11.63 \n0.003322259 \n\n\n\nsplit &lt;- initial_split(mydata, prop = 0.7, strata = \"weight\")\n\ntrain_data &lt;- training(split)\ntest_data &lt;- testing(split)"
  },
  {
    "objectID": "posts/my first post/subset selection/Ghimire_Ramesh.html#task-3",
    "href": "posts/my first post/subset selection/Ghimire_Ramesh.html#task-3",
    "title": "ADTA 5410 by Bulut",
    "section": "Task 3:",
    "text": "Task 3:\n\n\n\n\n\n\nTask 3\n\n\n\n\nIn this task, you will be using the train_data dataset to run a linear regression that takes weight as the dependent variable and all the other columns as the predictor.\n\nYou will use the lm() function to estimate your linear model and name it as linearmodel.\nUse the predict() function to predict the weight variable in the test_data dataset using linearmodel.\nStore the resulting predictions in a new object called predicted_weights_ols.\nCalculate the mean squared prediction error in the test_data dataset by comparing the predicted weight values with the actual weight values. Store the resulting value in an object called MSPE_linear.\n\nNeed Written Response: Print the value of MSPE_linear to the console using the print() function"
  },
  {
    "objectID": "posts/my first post/subset selection/Ghimire_Ramesh.html#your-code-for-task-3",
    "href": "posts/my first post/subset selection/Ghimire_Ramesh.html#your-code-for-task-3",
    "title": "ADTA 5410 by Bulut",
    "section": "Your code for Task 3",
    "text": "Your code for Task 3\n\n# Please provide your code for Task 3  in this code chunk\n\n\n# Linear model on training data \nlinearmodel &lt;- lm(weight ~ ., data = train_data)\n\n# Make predictions on test data\npredicted_weights_ols &lt;- predict(linearmodel, newdata = test_data)\n\n# Calculate MSPE\nMSPE_linear &lt;- mean((test_data$weight - predicted_weights_ols)^2)\n\n# Print MSPE\nprint(MSPE_linear)\n\n[1] 1.260889\n\n\nMSPE_linear = 1.2600889, indicates improved predictions on the unseen test dataset, affirming the efficacy of the model trained on the training dataset."
  },
  {
    "objectID": "posts/my first post/subset selection/Ghimire_Ramesh.html#task-4",
    "href": "posts/my first post/subset selection/Ghimire_Ramesh.html#task-4",
    "title": "ADTA 5410 by Bulut",
    "section": "Task 4:",
    "text": "Task 4:\n\n\n\n\n\n\nTask 4\n\n\n\n\nUse the gam function in the mgcv package to complete the same task. In other words, fit a Generalized additive model (GAM) on the train_data using the gam() function. Use the s() function for each suitable predictor. Save your R object as gam_model. If the gam output indicates that a variable should be added linearly to the model, then make the necessary changes in gam_model and explain your reasoning. As for the parameter tuning, let the package automatically selects the optimal lambda by using the method = “REML”.\nPrint out smoothing parameter from gam_model.\nUse the predict() function to predict the weight variable in the test_data dataset using gam_model. Store the resulting predictions in a new object called predicted_weights_gam.\nCalculate the mean squared prediction error in the test_data dataset by comparing the predicted ‘weight’ values with the actual weight values. Store the resulting value in an object called MSPE_gam.\n\nPrint the value of MSPE_gam to the console using the print() function."
  },
  {
    "objectID": "posts/my first post/subset selection/Ghimire_Ramesh.html#your-code-for-task-4",
    "href": "posts/my first post/subset selection/Ghimire_Ramesh.html#your-code-for-task-4",
    "title": "ADTA 5410 by Bulut",
    "section": "Your code for Task 4",
    "text": "Your code for Task 4\n\n# Please provide your code for Task 4 in this code chunk\n\nlibrary(mgcv)\n\n# Fit GAM model\ngam_model &lt;- gam(weight ~ s(fage) + s(mage) + s(weeks) + s(visits) + \n                  s(gained) + marital + gender + habit + whitemom, \n                data = train_data,\n                method = \"REML\")\n\n# Print smoothing parameters\nprint(summary(gam_model)$s.table)\n\n               edf   Ref.df            F     p-value\ns(fage)   1.001200 1.002396   2.08619167 0.148759470\ns(mage)   1.000388 1.000774   0.07901458 0.779096353\ns(weeks)  5.082104 6.147774 129.50469918 0.000000000\ns(visits) 3.119598 3.963131   1.66230248 0.132546087\ns(gained) 1.000384 1.000768   6.82021548 0.009196795\n\n\n\n# Make predictions on test set\npredicted_weights_gam &lt;- predict(gam_model, newdata = test_data)\n\n# Calculate MSPE \nMSPE_gam &lt;- mean((test_data$weight - predicted_weights_gam)^2)\n\n# Print MSPE\nprint(MSPE_gam)\n\n[1] 1.16755\n\n\nMSPE_gam = 1.16755, reflects lower error and improved predictions in the GAM model, attributed to the incorporation of non-linear smoothing functions for continuous predictors."
  },
  {
    "objectID": "posts/my first post/subset selection/Ghimire_Ramesh.html#task-5",
    "href": "posts/my first post/subset selection/Ghimire_Ramesh.html#task-5",
    "title": "ADTA 5410 by Bulut",
    "section": "TASK 5:",
    "text": "TASK 5:\n\n\n\n\n\n\nTask 5\n\n\n\n\nEvaluate the effectiveness of the linear regression model (linearmodel) and the generalized additive model (gam_model) by comparing their Mean Squared Prediction Errors (MSPE). Utilize the values MSPE_linear and MSPE_gam, which were derived in previous tasks, to assess which model more accurately predicts the ‘weight’ variable in the test_data dataset. The model with the lower MSPE value will be considered as having superior predictive performance for this specific variable.\nInsert your written response in here:"
  },
  {
    "objectID": "posts/my first post/subset selection/Ghimire_Ramesh.html#your-code-for-task-5",
    "href": "posts/my first post/subset selection/Ghimire_Ramesh.html#your-code-for-task-5",
    "title": "ADTA 5410 by Bulut",
    "section": "Your code for Task 5",
    "text": "Your code for Task 5\n\n# Linear Regression MSPE: MSPE_linear = 1.260889\n\n# GAM Model MSPE: MSPE_gam = 1.16755\n\nLinear Regression MSPE: 1.260889\nGAM Model MSPE: 1.16755\nA lower MSPE signifies enhanced predictive accuracy for the ‘weight’ variable in the test dataset. In this comparison:\n\nIf MSPE_linear &lt; MSPE_gam: Linear regression outperforms in predictive performance.\nIf MSPE_gam &lt; MSPE_linear: The generalized additive model excels in predictive performance.\nIf MSPE_linear ≈ MSPE_gam: Both models perform similarly in predicting the ‘weight’ variable.\n\nAnalysis reveals the GAM model’s superiority with a lower MSPE of 1.117023, indicating reduced deviation between actual and predicted values."
  },
  {
    "objectID": "posts/my first post/Ghimire_Ramesh.html#section-1",
    "href": "posts/my first post/Ghimire_Ramesh.html#section-1",
    "title": "R project",
    "section": "",
    "text": "# Display the structure of the dataset\nstr(mydata)\n\n'data.frame':   999 obs. of  12 variables:\n $ fage    : int  NA NA 19 21 NA NA 18 17 NA 20 ...\n $ mage    : int  13 14 15 15 15 15 15 15 16 16 ...\n $ mature  : chr  \"younger mom\" \"younger mom\" \"younger mom\" \"younger mom\" ...\n $ weeks   : int  39 42 37 41 39 38 37 35 38 37 ...\n $ premie  : chr  \"full term\" \"full term\" \"full term\" \"full term\" ...\n $ visits  : int  10 15 11 6 9 19 12 5 9 13 ...\n $ marital : chr  \"married\" \"married\" \"married\" \"married\" ...\n $ gained  : int  38 20 38 34 27 22 76 15 NA 52 ...\n $ weight  : num  7.63 7.88 6.63 8 6.38 5.38 8.44 4.69 8.81 6.94 ...\n $ gender  : chr  \"male\" \"male\" \"female\" \"male\" ...\n $ habit   : chr  \"nonsmoker\" \"nonsmoker\" \"nonsmoker\" \"nonsmoker\" ...\n $ whitemom: chr  \"not white\" \"not white\" \"white\" \"white\" ...\n\n\n\n# Summary statistics for numeric variables\nsummary(mydata)\n\n      fage            mage          mature              weeks      \n Min.   :14.00   Min.   :13.00   Length:999         Min.   :20.00  \n 1st Qu.:25.00   1st Qu.:22.00   Class :character   1st Qu.:37.00  \n Median :30.00   Median :27.00   Mode  :character   Median :39.00  \n Mean   :30.26   Mean   :26.99                      Mean   :38.33  \n 3rd Qu.:35.00   3rd Qu.:32.00                      3rd Qu.:40.00  \n Max.   :55.00   Max.   :50.00                      Max.   :45.00  \n NA's   :170                                        NA's   :1      \n    premie              visits       marital              gained     \n Length:999         Min.   : 0.0   Length:999         Min.   : 0.00  \n Class :character   1st Qu.:10.0   Class :character   1st Qu.:20.00  \n Mode  :character   Median :12.0   Mode  :character   Median :30.00  \n                    Mean   :12.1                      Mean   :30.33  \n                    3rd Qu.:15.0                      3rd Qu.:38.00  \n                    Max.   :30.0                      Max.   :85.00  \n                    NA's   :8                         NA's   :26     \n     weight          gender             habit             whitemom        \n Min.   : 1.000   Length:999         Length:999         Length:999        \n 1st Qu.: 6.380   Class :character   Class :character   Class :character  \n Median : 7.310   Mode  :character   Mode  :character   Mode  :character  \n Mean   : 7.104                                                           \n 3rd Qu.: 8.060                                                           \n Max.   :11.750                                                           \n                                                                          \n\n\n\n# Check class/type of each variable\nsapply(mydata, class)\n\n       fage        mage      mature       weeks      premie      visits \n  \"integer\"   \"integer\" \"character\"   \"integer\" \"character\"   \"integer\" \n    marital      gained      weight      gender       habit    whitemom \n\"character\"   \"integer\"   \"numeric\" \"character\" \"character\" \"character\" \n\n\n\n# Check factor levels for factor variables\nsapply(mydata, function(x) if(is.factor(x)) levels(x))\n\n$fage\nNULL\n\n$mage\nNULL\n\n$mature\nNULL\n\n$weeks\nNULL\n\n$premie\nNULL\n\n$visits\nNULL\n\n$marital\nNULL\n\n$gained\nNULL\n\n$weight\nNULL\n\n$gender\nNULL\n\n$habit\nNULL\n\n$whitemom\nNULL\n\n\n\n# Recode variables as needed\nmydata$mature &lt;- as.factor(mydata$mature)\nmydata$premie &lt;- as.factor(mydata$premie) \n\n\n# Confirm classes after recoding\nsapply(mydata, class)\n\n       fage        mage      mature       weeks      premie      visits \n  \"integer\"   \"integer\"    \"factor\"   \"integer\"    \"factor\"   \"integer\" \n    marital      gained      weight      gender       habit    whitemom \n\"character\"   \"integer\"   \"numeric\" \"character\" \"character\" \"character\" \n\n\n\nlibrary(dplyr)\nlibrary(tidyr)\n\n# Identify missing values\nsapply(mydata, function(x) sum(is.na(x)))\n\n    fage     mage   mature    weeks   premie   visits  marital   gained \n     170        0        0        1        1        8        0       26 \n  weight   gender    habit whitemom \n       0        0        0        2 \n\n\n\n# Numeric variables - fill with median\nnum_vars &lt;- c(\"fage\", \"mage\", \"weeks\", \"visits\", \"gained\", \"weight\")\nfor(v in num_vars) {\n  med &lt;- median(mydata[[v]], na.rm = TRUE) \n  mydata[[v]][is.na(mydata[[v]])] &lt;- med\n}\n\n\n# Categorical variables - fill with mode \ncat_vars &lt;- c(\"mature\", \"premie\", \"marital\", \"gender\", \"habit\", \"whitemom\")\nfor(v in cat_vars) {\n  mod &lt;- names(which.max(table(mydata[[v]])))\n  mydata[[v]][is.na(mydata[[v]])] &lt;- mod  \n}\n\n\n# Check if any NAs remain\nsapply(mydata, function(x) sum(is.na(x)))\n\n    fage     mage   mature    weeks   premie   visits  marital   gained \n       0        0        0        0        0        0        0        0 \n  weight   gender    habit whitemom \n       0        0        0        0 \n\n\n\n# Determine variable with highest correlation\ncor_mat &lt;- cor(mydata[sapply(mydata, is.numeric)], use=\"pairwise.complete.obs\")\nhighest_cor &lt;- which.max(abs(cor_mat[\"weight\",]))\nnames(highest_cor) \n\n[1] \"weight\"\n\n# Plot scatterplot \ntarget_var &lt;- \"weight\"\npred_var &lt;- names(highest_cor)\n\nggplot(mydata, aes_string(x = pred_var, y = target_var)) + \n  geom_point(alpha = 0.5) +\n  ggtitle(paste0(\"Scatterplot of \", target_var, \" vs \", pred_var))\n\nWarning: `aes_string()` was deprecated in ggplot2 3.0.0.\nℹ Please use tidy evaluation idioms with `aes()`.\nℹ See also `vignette(\"ggplot2-in-packages\")` for more information.\n\n\n\n\n\nWeight gained exhibits the highest absolute correlation with birth weight. The graph illustrates a positive correlation, indicating that mothers who gained extra weight during pregnancy tended to have babies with higher weights. Although there are a few outliers, the general trend suggests that weight gain during pregnancy supports fetal development."
  },
  {
    "objectID": "posts/my first post/Ghimire_Ramesh.html#section-3",
    "href": "posts/my first post/Ghimire_Ramesh.html#section-3",
    "title": "R project",
    "section": "",
    "text": "# Please provide your code for Task 2 in this code chunk\n# split the sample by using rsample package\n\n# Split the data into a training set (70%) and a test set (30%)\nset.seed(123456)\n\n# Load rsample package\nlibrary(rsample)\n\n# Take a 70/30 split stratified on weight \nsplit &lt;- initial_split(mydata, prop = 0.7, strata = \"weight\")\n\n# Extract training and test sets\ntrain_data &lt;- training(split) \ntest_data &lt;- testing(split)\n\n# Check proportions\nprop.table(table(train_data$weight)) \n\n\n          1        1.19        1.31        1.38        1.44         1.5 \n0.001432665 0.001432665 0.001432665 0.002865330 0.001432665 0.002865330 \n       1.56        1.69        2.25         2.5        2.63        2.69 \n0.001432665 0.002865330 0.001432665 0.001432665 0.001432665 0.001432665 \n       2.88        2.94           3        3.19        3.25        3.31 \n0.004297994 0.001432665 0.001432665 0.001432665 0.001432665 0.001432665 \n       3.56        3.63        3.75        3.81        3.94           4 \n0.001432665 0.001432665 0.002865330 0.001432665 0.001432665 0.001432665 \n       4.06        4.13        4.19        4.25        4.31        4.44 \n0.002865330 0.002865330 0.001432665 0.001432665 0.001432665 0.004297994 \n        4.5        4.56        4.63        4.69        4.75        4.88 \n0.002865330 0.002865330 0.002865330 0.005730659 0.007163324 0.001432665 \n       4.94           5        5.06        5.13        5.19        5.25 \n0.001432665 0.002865330 0.002865330 0.002865330 0.001432665 0.004297994 \n       5.38        5.44         5.5        5.56        5.63        5.69 \n0.010028653 0.007163324 0.008595989 0.002865330 0.008595989 0.004297994 \n       5.75        5.81        5.88        5.94           6        6.06 \n0.004297994 0.007163324 0.007163324 0.017191977 0.014326648 0.008595989 \n       6.13        6.19        6.25        6.31        6.38        6.44 \n0.005730659 0.011461318 0.011461318 0.014326648 0.017191977 0.005730659 \n        6.5        6.56        6.63        6.69        6.75        6.81 \n0.015759312 0.015759312 0.010028653 0.008595989 0.020057307 0.012893983 \n       6.88        6.94           7        7.06        7.13        7.19 \n0.021489971 0.017191977 0.022922636 0.020057307 0.018624642 0.021489971 \n       7.25        7.31        7.38        7.44         7.5        7.56 \n0.024355301 0.030085960 0.022922636 0.031518625 0.022922636 0.024355301 \n       7.63        7.69        7.75        7.81        7.88        7.94 \n0.014326648 0.015759312 0.015759312 0.021489971 0.027220630 0.014326648 \n          8        8.06        8.13        8.19        8.25        8.31 \n0.018624642 0.010028653 0.020057307 0.020057307 0.020057307 0.012893983 \n       8.38        8.44         8.5        8.56        8.63        8.69 \n0.021489971 0.007163324 0.015759312 0.011461318 0.005730659 0.005730659 \n       8.75        8.81        8.88        8.94           9        9.06 \n0.010028653 0.011461318 0.010028653 0.005730659 0.007163324 0.005730659 \n       9.13        9.19        9.25        9.31        9.38         9.5 \n0.007163324 0.007163324 0.004297994 0.002865330 0.001432665 0.002865330 \n       9.56        9.63        9.75        9.81        9.88        9.94 \n0.004297994 0.002865330 0.001432665 0.001432665 0.004297994 0.001432665 \n      10.06       10.13       10.19       10.25       11.75 \n0.001432665 0.001432665 0.001432665 0.001432665 0.001432665 \n\nprop.table(table(test_data$weight))\n\n\n          1        1.38        1.44        1.63        1.88        2.19 \n0.003322259 0.003322259 0.003322259 0.003322259 0.003322259 0.003322259 \n       2.25        2.69        3.44        3.94           4         4.5 \n0.003322259 0.003322259 0.003322259 0.003322259 0.003322259 0.003322259 \n       4.56        4.75        4.94           5        5.06        5.19 \n0.006644518 0.003322259 0.003322259 0.006644518 0.003322259 0.003322259 \n       5.25        5.38        5.44         5.5        5.56        5.63 \n0.003322259 0.003322259 0.006644518 0.003322259 0.009966777 0.006644518 \n       5.69        5.75        5.81        5.88        5.94           6 \n0.003322259 0.003322259 0.013289037 0.023255814 0.009966777 0.016611296 \n       6.06        6.13        6.19        6.25        6.31        6.38 \n0.013289037 0.006644518 0.009966777 0.026578073 0.016611296 0.013289037 \n       6.44         6.5        6.56        6.63        6.69        6.75 \n0.013289037 0.013289037 0.006644518 0.006644518 0.023255814 0.029900332 \n       6.81        6.88        6.94           7        7.06        7.13 \n0.009966777 0.033222591 0.006644518 0.019933555 0.019933555 0.036544850 \n       7.19        7.25        7.31        7.38        7.44         7.5 \n0.019933555 0.016611296 0.009966777 0.016611296 0.026578073 0.026578073 \n       7.56        7.63        7.69        7.75        7.81        7.88 \n0.006644518 0.026578073 0.019933555 0.019933555 0.016611296 0.019933555 \n       7.94           8        8.06        8.13        8.19        8.25 \n0.019933555 0.019933555 0.019933555 0.009966777 0.009966777 0.006644518 \n       8.31        8.38        8.44         8.5        8.56        8.63 \n0.009966777 0.016611296 0.029900332 0.013289037 0.009966777 0.003322259 \n       8.75        8.81        8.88           9        9.06        9.13 \n0.023255814 0.013289037 0.006644518 0.009966777 0.006644518 0.006644518 \n       9.19        9.25        9.31        9.38         9.5        9.63 \n0.006644518 0.009966777 0.009966777 0.003322259 0.006644518 0.003322259 \n       9.69        9.75        9.88       10.06       10.13       10.38 \n0.003322259 0.003322259 0.003322259 0.003322259 0.003322259 0.003322259 \n      11.63 \n0.003322259 \n\n\n\nsplit &lt;- initial_split(mydata, prop = 0.7, strata = \"weight\")\n\ntrain_data &lt;- training(split)\ntest_data &lt;- testing(split)"
  },
  {
    "objectID": "posts/my first post/Ghimire_Ramesh.html#section-4",
    "href": "posts/my first post/Ghimire_Ramesh.html#section-4",
    "title": "R project",
    "section": "",
    "text": "# Please provide your code for Task 3  in this code chunk\n\n\n# Linear model on training data \nlinearmodel &lt;- lm(weight ~ ., data = train_data)\n\n# Make predictions on test data\npredicted_weights_ols &lt;- predict(linearmodel, newdata = test_data)\n\n# Calculate MSPE\nMSPE_linear &lt;- mean((test_data$weight - predicted_weights_ols)^2)\n\n# Print MSPE\nprint(MSPE_linear)\n\n[1] 1.260889\n\n\nMSPE_linear = 1.2600889, indicates improved predictions on the unseen test dataset, affirming the efficacy of the model trained on the training dataset."
  },
  {
    "objectID": "posts/my first post/Ghimire_Ramesh.html#section-5",
    "href": "posts/my first post/Ghimire_Ramesh.html#section-5",
    "title": "R project",
    "section": "",
    "text": "# Please provide your code for Task 4 in this code chunk\n\nlibrary(mgcv)\n\n# Fit GAM model\ngam_model &lt;- gam(weight ~ s(fage) + s(mage) + s(weeks) + s(visits) + \n                  s(gained) + marital + gender + habit + whitemom, \n                data = train_data,\n                method = \"REML\")\n\n# Print smoothing parameters\nprint(summary(gam_model)$s.table)\n\n               edf   Ref.df            F     p-value\ns(fage)   1.001200 1.002396   2.08619167 0.148759470\ns(mage)   1.000388 1.000774   0.07901458 0.779096353\ns(weeks)  5.082104 6.147774 129.50469918 0.000000000\ns(visits) 3.119598 3.963131   1.66230248 0.132546087\ns(gained) 1.000384 1.000768   6.82021548 0.009196795\n\n\n\n# Make predictions on test set\npredicted_weights_gam &lt;- predict(gam_model, newdata = test_data)\n\n# Calculate MSPE \nMSPE_gam &lt;- mean((test_data$weight - predicted_weights_gam)^2)\n\n# Print MSPE\nprint(MSPE_gam)\n\n[1] 1.16755\n\n\nMSPE_gam = 1.16755, reflects lower error and improved predictions in the GAM model, attributed to the incorporation of non-linear smoothing functions for continuous predictors."
  },
  {
    "objectID": "posts/my first post/Ghimire_Ramesh.html#section-6",
    "href": "posts/my first post/Ghimire_Ramesh.html#section-6",
    "title": "R project",
    "section": "",
    "text": "# Linear Regression MSPE: MSPE_linear = 1.260889\n\n# GAM Model MSPE: MSPE_gam = 1.16755\n\nLinear Regression MSPE: 1.260889\nGAM Model MSPE: 1.16755\nA lower MSPE signifies enhanced predictive accuracy for the ‘weight’ variable in the test dataset. In this comparison:\n\nIf MSPE_linear &lt; MSPE_gam: Linear regression outperforms in predictive performance.\nIf MSPE_gam &lt; MSPE_linear: The generalized additive model excels in predictive performance.\nIf MSPE_linear ≈ MSPE_gam: Both models perform similarly in predicting the ‘weight’ variable.\n\nAnalysis reveals the GAM model’s superiority with a lower MSPE of 1.117023, indicating reduced deviation between actual and predicted values."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ramesh Ghimire",
    "section": "",
    "text": "hello\n\n\n\n\n\n\n\n\n  \n\n\n\n\nR project\n\n\n\n\n\n\n\n\n\n\n\n\nRamesh Ghimire\n\n\n\n\n\n\n  \n\n\n\n\nADTA 5410 by Bulut\n\n\n\n\n\n\n\n\n\n\n\n\nRamesh Ghimire\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nLinear regression\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nDec 14, 2023\n\n\nRamesh Ghimire\n\n\n\n\n\n\n  \n\n\n\n\nWelcome to my Blog\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nDec 11, 2023\n\n\nRamesh Ghimire\n\n\n\n\n\n\nNo matching items"
  }
]