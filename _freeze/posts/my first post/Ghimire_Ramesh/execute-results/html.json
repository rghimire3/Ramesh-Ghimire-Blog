{
  "hash": "7984c46ddfc2916ded451f5c6badd587",
  "result": {
    "markdown": "---\ntitle: \"ADTA 5410 by Bulut\"\nauthor: \"Ramesh Ghimire\"\nformat: html\neditor: visual\n---\n\n::: {.cell}\n\n:::\n\n\n## \n\n## Business Problem\n\nWe'll be exploring the 2004 North Carolina birth records. Our focus will be on examining the connection between the behaviors and routines of pregnant mothers and the outcomes of their childbirth. Please note, the dataset we'll be using is a randomly selected subset of the original dataset.\n\n**Attributes:**\n\n-   **Predictors**\n\n    -   **fage**: father's age in years.\n\n    -   **mage**: mother's age in years.\n\n    -   **mature**: maturity status of mother.\n\n    -   **weeks**: length of pregnancy in weeks.\n\n    -   **premie**: whether the birth was classified as premature (premie) or full-term.\n\n    -   **visits**: number of hospital visits during pregnancy.\n\n    -   **marital**: whether mother is married or not married at birth.\n\n    -   **gained**: weight gained by mother during pregnancy in pounds.\n\n    -   **gender**: gender of the baby, female or male.\n\n    -   **habit**: status of the mother as a nonsmoker or a smoker.\n\n    -   **whitemom**: whether mother is white or not white.\n\n**Outcome Variable:**\n\n-   **weight**: weight of the baby at birth in pounds. (Regression problem)\n\n#### Do not change anything in this r chunk. Just run the code chunk and move to the next one\n\n\n::: {.cell}\n\n:::\n\n\n## Task 1: Data Preparation\n\n::: {.callout-important appearance=\"simple\"}\n## Task 1\n\n1.  **Data Structure Check**:\n\n    -   Examine the variable descriptions and the overall structure of the dataset in **`mydata`**.\n\n    -   Ensure that each variable is correctly coded in the R object. Specifically, numeric variables should be in numeric format, and factor variables should be coded as factors.\n\n2.  **Handling Missing Values**:\n\n    -   Identify and replace missing values in your dataset.\n\n        -   For numeric variables, fill missing values with the median of that variable.\n\n        -   For categorical variables, use the most frequent category (mode) to replace missing values.\n\n3.  **Correlation Analysis and Visualization**:\n\n    -   Determine the variable that has the highest correlation (in absolute value) with your chosen target variable.\n\n    -   Create a scatter plot to visually represent the relationship between these two variables.\n\n    -   Provide a brief commentary on the scatter plot. Discuss any notable patterns, trends, or insights you observe.\n\n    -   **Insert your written response in here:**\n:::\n\n## Your code for Task 1\n\n1.  **Data Structure Check**:\n\n    -   Examine the variable descriptions and the overall structure of the dataset in **`mydata`**.\n\n    -   Ensure that each variable is correctly coded in the R object. Specifically, numeric variables should be in numeric format, and factor variables should be coded as factors.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Display the structure of the dataset\nstr(mydata)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n'data.frame':\t999 obs. of  12 variables:\n $ fage    : int  NA NA 19 21 NA NA 18 17 NA 20 ...\n $ mage    : int  13 14 15 15 15 15 15 15 16 16 ...\n $ mature  : chr  \"younger mom\" \"younger mom\" \"younger mom\" \"younger mom\" ...\n $ weeks   : int  39 42 37 41 39 38 37 35 38 37 ...\n $ premie  : chr  \"full term\" \"full term\" \"full term\" \"full term\" ...\n $ visits  : int  10 15 11 6 9 19 12 5 9 13 ...\n $ marital : chr  \"married\" \"married\" \"married\" \"married\" ...\n $ gained  : int  38 20 38 34 27 22 76 15 NA 52 ...\n $ weight  : num  7.63 7.88 6.63 8 6.38 5.38 8.44 4.69 8.81 6.94 ...\n $ gender  : chr  \"male\" \"male\" \"female\" \"male\" ...\n $ habit   : chr  \"nonsmoker\" \"nonsmoker\" \"nonsmoker\" \"nonsmoker\" ...\n $ whitemom: chr  \"not white\" \"not white\" \"white\" \"white\" ...\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Summary statistics for numeric variables\nsummary(mydata)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      fage            mage          mature              weeks      \n Min.   :14.00   Min.   :13.00   Length:999         Min.   :20.00  \n 1st Qu.:25.00   1st Qu.:22.00   Class :character   1st Qu.:37.00  \n Median :30.00   Median :27.00   Mode  :character   Median :39.00  \n Mean   :30.26   Mean   :26.99                      Mean   :38.33  \n 3rd Qu.:35.00   3rd Qu.:32.00                      3rd Qu.:40.00  \n Max.   :55.00   Max.   :50.00                      Max.   :45.00  \n NA's   :170                                        NA's   :1      \n    premie              visits       marital              gained     \n Length:999         Min.   : 0.0   Length:999         Min.   : 0.00  \n Class :character   1st Qu.:10.0   Class :character   1st Qu.:20.00  \n Mode  :character   Median :12.0   Mode  :character   Median :30.00  \n                    Mean   :12.1                      Mean   :30.33  \n                    3rd Qu.:15.0                      3rd Qu.:38.00  \n                    Max.   :30.0                      Max.   :85.00  \n                    NA's   :8                         NA's   :26     \n     weight          gender             habit             whitemom        \n Min.   : 1.000   Length:999         Length:999         Length:999        \n 1st Qu.: 6.380   Class :character   Class :character   Class :character  \n Median : 7.310   Mode  :character   Mode  :character   Mode  :character  \n Mean   : 7.104                                                           \n 3rd Qu.: 8.060                                                           \n Max.   :11.750                                                           \n                                                                          \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Check class/type of each variable\nsapply(mydata, class)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       fage        mage      mature       weeks      premie      visits \n  \"integer\"   \"integer\" \"character\"   \"integer\" \"character\"   \"integer\" \n    marital      gained      weight      gender       habit    whitemom \n\"character\"   \"integer\"   \"numeric\" \"character\" \"character\" \"character\" \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Check factor levels for factor variables\nsapply(mydata, function(x) if(is.factor(x)) levels(x))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$fage\nNULL\n\n$mage\nNULL\n\n$mature\nNULL\n\n$weeks\nNULL\n\n$premie\nNULL\n\n$visits\nNULL\n\n$marital\nNULL\n\n$gained\nNULL\n\n$weight\nNULL\n\n$gender\nNULL\n\n$habit\nNULL\n\n$whitemom\nNULL\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Recode variables as needed\nmydata$mature <- as.factor(mydata$mature)\nmydata$premie <- as.factor(mydata$premie) \n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Confirm classes after recoding\nsapply(mydata, class)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       fage        mage      mature       weeks      premie      visits \n  \"integer\"   \"integer\"    \"factor\"   \"integer\"    \"factor\"   \"integer\" \n    marital      gained      weight      gender       habit    whitemom \n\"character\"   \"integer\"   \"numeric\" \"character\" \"character\" \"character\" \n```\n:::\n:::\n\n\n1.  **Handling Missing Values**:\n\n    -   Identify and replace missing values in your dataset.\n\n        -   For numeric variables, fill missing values with the median of that variable.\n\n        -   For categorical variables, use the most frequent category (mode) to replace missing values.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(tidyr)\n\n# Identify missing values\nsapply(mydata, function(x) sum(is.na(x)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    fage     mage   mature    weeks   premie   visits  marital   gained \n     170        0        0        1        1        8        0       26 \n  weight   gender    habit whitemom \n       0        0        0        2 \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Numeric variables - fill with median\nnum_vars <- c(\"fage\", \"mage\", \"weeks\", \"visits\", \"gained\", \"weight\")\nfor(v in num_vars) {\n  med <- median(mydata[[v]], na.rm = TRUE) \n  mydata[[v]][is.na(mydata[[v]])] <- med\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Categorical variables - fill with mode \ncat_vars <- c(\"mature\", \"premie\", \"marital\", \"gender\", \"habit\", \"whitemom\")\nfor(v in cat_vars) {\n  mod <- names(which.max(table(mydata[[v]])))\n  mydata[[v]][is.na(mydata[[v]])] <- mod  \n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Check if any NAs remain\nsapply(mydata, function(x) sum(is.na(x)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    fage     mage   mature    weeks   premie   visits  marital   gained \n       0        0        0        0        0        0        0        0 \n  weight   gender    habit whitemom \n       0        0        0        0 \n```\n:::\n:::\n\n\n**Correlation Analysis and Visualization**:\n\n-   Determine the variable that has the highest correlation (in absolute value) with your chosen target variable.\n\n-   Create a scatter plot to visually represent the relationship between these two variables.\n\n-   Provide a brief commentary on the scatter plot. Discuss any notable patterns, trends, or insights you observe.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Determine variable with highest correlation\ncor_mat <- cor(mydata[sapply(mydata, is.numeric)], use=\"pairwise.complete.obs\")\nhighest_cor <- which.max(abs(cor_mat[\"weight\",]))\nnames(highest_cor) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"weight\"\n```\n:::\n\n```{.r .cell-code}\n# Plot scatterplot \ntarget_var <- \"weight\"\npred_var <- names(highest_cor)\n\nggplot(mydata, aes_string(x = pred_var, y = target_var)) + \n  geom_point(alpha = 0.5) +\n  ggtitle(paste0(\"Scatterplot of \", target_var, \" vs \", pred_var))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: `aes_string()` was deprecated in ggplot2 3.0.0.\nℹ Please use tidy evaluation idioms with `aes()`.\nℹ See also `vignette(\"ggplot2-in-packages\")` for more information.\n```\n:::\n\n::: {.cell-output-display}\n![](Ghimire_Ramesh_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\nWeight gained exhibits the highest absolute correlation with birth weight. The graph illustrates a positive correlation, indicating that mothers who gained extra weight during pregnancy tended to have babies with higher weights. Although there are a few outliers, the general trend suggests that weight gain during pregnancy supports fetal development.\n\n## Task 2: Data Splitting\n\n------------------------------------------------------------------------\n\n::: {.callout-important appearance=\"simple\"}\n## Task 2\n\n-   Prior to starting our analysis, we will divide our dataset into two parts: a training set and a test set. For this lab assignment, you'll need to use the **`initial_split`** function from the **`rsample`** package in R to partition the data. Please ensure to use **`set.seed(123456)`** for reproducibility. Allocate 70% of the data to the training set and go with the default options in initial_split function. Conduct stratified sampling by using `strata=\"weight\"`.\n\n-   Name your training set **`train_data`** and your test set **`test_data`**. This division will be crucial for our analysis, allowing us to train our models effectively and test their performance.\n:::\n\n## Your code for Task 2\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Please provide your code for Task 2 in this code chunk\n# split the sample by using rsample package\n\n# Split the data into a training set (70%) and a test set (30%)\nset.seed(123456)\n\n# Load rsample package\nlibrary(rsample)\n\n# Take a 70/30 split stratified on weight \nsplit <- initial_split(mydata, prop = 0.7, strata = \"weight\")\n\n# Extract training and test sets\ntrain_data <- training(split) \ntest_data <- testing(split)\n\n# Check proportions\nprop.table(table(train_data$weight)) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n          1        1.19        1.31        1.38        1.44         1.5 \n0.001432665 0.001432665 0.001432665 0.002865330 0.001432665 0.002865330 \n       1.56        1.69        2.25         2.5        2.63        2.69 \n0.001432665 0.002865330 0.001432665 0.001432665 0.001432665 0.001432665 \n       2.88        2.94           3        3.19        3.25        3.31 \n0.004297994 0.001432665 0.001432665 0.001432665 0.001432665 0.001432665 \n       3.56        3.63        3.75        3.81        3.94           4 \n0.001432665 0.001432665 0.002865330 0.001432665 0.001432665 0.001432665 \n       4.06        4.13        4.19        4.25        4.31        4.44 \n0.002865330 0.002865330 0.001432665 0.001432665 0.001432665 0.004297994 \n        4.5        4.56        4.63        4.69        4.75        4.88 \n0.002865330 0.002865330 0.002865330 0.005730659 0.007163324 0.001432665 \n       4.94           5        5.06        5.13        5.19        5.25 \n0.001432665 0.002865330 0.002865330 0.002865330 0.001432665 0.004297994 \n       5.38        5.44         5.5        5.56        5.63        5.69 \n0.010028653 0.007163324 0.008595989 0.002865330 0.008595989 0.004297994 \n       5.75        5.81        5.88        5.94           6        6.06 \n0.004297994 0.007163324 0.007163324 0.017191977 0.014326648 0.008595989 \n       6.13        6.19        6.25        6.31        6.38        6.44 \n0.005730659 0.011461318 0.011461318 0.014326648 0.017191977 0.005730659 \n        6.5        6.56        6.63        6.69        6.75        6.81 \n0.015759312 0.015759312 0.010028653 0.008595989 0.020057307 0.012893983 \n       6.88        6.94           7        7.06        7.13        7.19 \n0.021489971 0.017191977 0.022922636 0.020057307 0.018624642 0.021489971 \n       7.25        7.31        7.38        7.44         7.5        7.56 \n0.024355301 0.030085960 0.022922636 0.031518625 0.022922636 0.024355301 \n       7.63        7.69        7.75        7.81        7.88        7.94 \n0.014326648 0.015759312 0.015759312 0.021489971 0.027220630 0.014326648 \n          8        8.06        8.13        8.19        8.25        8.31 \n0.018624642 0.010028653 0.020057307 0.020057307 0.020057307 0.012893983 \n       8.38        8.44         8.5        8.56        8.63        8.69 \n0.021489971 0.007163324 0.015759312 0.011461318 0.005730659 0.005730659 \n       8.75        8.81        8.88        8.94           9        9.06 \n0.010028653 0.011461318 0.010028653 0.005730659 0.007163324 0.005730659 \n       9.13        9.19        9.25        9.31        9.38         9.5 \n0.007163324 0.007163324 0.004297994 0.002865330 0.001432665 0.002865330 \n       9.56        9.63        9.75        9.81        9.88        9.94 \n0.004297994 0.002865330 0.001432665 0.001432665 0.004297994 0.001432665 \n      10.06       10.13       10.19       10.25       11.75 \n0.001432665 0.001432665 0.001432665 0.001432665 0.001432665 \n```\n:::\n\n```{.r .cell-code}\nprop.table(table(test_data$weight))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n          1        1.38        1.44        1.63        1.88        2.19 \n0.003322259 0.003322259 0.003322259 0.003322259 0.003322259 0.003322259 \n       2.25        2.69        3.44        3.94           4         4.5 \n0.003322259 0.003322259 0.003322259 0.003322259 0.003322259 0.003322259 \n       4.56        4.75        4.94           5        5.06        5.19 \n0.006644518 0.003322259 0.003322259 0.006644518 0.003322259 0.003322259 \n       5.25        5.38        5.44         5.5        5.56        5.63 \n0.003322259 0.003322259 0.006644518 0.003322259 0.009966777 0.006644518 \n       5.69        5.75        5.81        5.88        5.94           6 \n0.003322259 0.003322259 0.013289037 0.023255814 0.009966777 0.016611296 \n       6.06        6.13        6.19        6.25        6.31        6.38 \n0.013289037 0.006644518 0.009966777 0.026578073 0.016611296 0.013289037 \n       6.44         6.5        6.56        6.63        6.69        6.75 \n0.013289037 0.013289037 0.006644518 0.006644518 0.023255814 0.029900332 \n       6.81        6.88        6.94           7        7.06        7.13 \n0.009966777 0.033222591 0.006644518 0.019933555 0.019933555 0.036544850 \n       7.19        7.25        7.31        7.38        7.44         7.5 \n0.019933555 0.016611296 0.009966777 0.016611296 0.026578073 0.026578073 \n       7.56        7.63        7.69        7.75        7.81        7.88 \n0.006644518 0.026578073 0.019933555 0.019933555 0.016611296 0.019933555 \n       7.94           8        8.06        8.13        8.19        8.25 \n0.019933555 0.019933555 0.019933555 0.009966777 0.009966777 0.006644518 \n       8.31        8.38        8.44         8.5        8.56        8.63 \n0.009966777 0.016611296 0.029900332 0.013289037 0.009966777 0.003322259 \n       8.75        8.81        8.88           9        9.06        9.13 \n0.023255814 0.013289037 0.006644518 0.009966777 0.006644518 0.006644518 \n       9.19        9.25        9.31        9.38         9.5        9.63 \n0.006644518 0.009966777 0.009966777 0.003322259 0.006644518 0.003322259 \n       9.69        9.75        9.88       10.06       10.13       10.38 \n0.003322259 0.003322259 0.003322259 0.003322259 0.003322259 0.003322259 \n      11.63 \n0.003322259 \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsplit <- initial_split(mydata, prop = 0.7, strata = \"weight\")\n\ntrain_data <- training(split)\ntest_data <- testing(split)\n```\n:::\n\n\n## Task 3:\n\n::: {.callout-important appearance=\"simple\"}\n## Task 3\n\n-   In this task, you will be using the **`train_data`** dataset to run a linear regression that takes `weight` as the dependent variable and all the other columns as the predictor.\n\n    -   You will use the **`lm()`** function to estimate your linear model and name it as **`linearmodel`**.\n\n    -   Use the **`predict()`** function to predict the `weight` variable in the **`test_data`** dataset using **`linearmodel`**.\n\n    -   Store the resulting predictions in a new object called **`predicted_weights_ols`**.\n\n    -   Calculate the mean squared prediction error in the **`test_data`** dataset by comparing the predicted `weight` values with the actual `weight` values. Store the resulting value in an object called **`MSPE_linear`**.\n\n-   **Need Written Response:** Print the value of **`MSPE_linear`** to the console using the **`print()`** function\n:::\n\n## Your code for Task 3\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Please provide your code for Task 3  in this code chunk\n\n\n# Linear model on training data \nlinearmodel <- lm(weight ~ ., data = train_data)\n\n# Make predictions on test data\npredicted_weights_ols <- predict(linearmodel, newdata = test_data)\n\n# Calculate MSPE\nMSPE_linear <- mean((test_data$weight - predicted_weights_ols)^2)\n\n# Print MSPE\nprint(MSPE_linear)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1.260889\n```\n:::\n:::\n\n\nMSPE_linear = 1.2600889, indicates improved predictions on the unseen test dataset, affirming the efficacy of the model trained on the training dataset.\n\n## Task 4:\n\n::: {.callout-important appearance=\"simple\"}\n## Task 4\n\n-   Use the `gam` function in the **`mgcv`** package to complete the same task. In other words, fit a Generalized additive model (GAM) on the `train_data` using the **`gam()`** function. Use the **`s()`** function for each **suitable** predictor. Save your R object as `gam_model.` If the `gam` output indicates that a variable should be added linearly to the model, then make the necessary changes in `gam_model` and explain your reasoning. As for the parameter tuning, let the package automatically selects the optimal lambda by using the method = \"REML\".\n-   Print out smoothing parameter from `gam_model.`\n-   Use the **`predict()`** function to predict the `weight` variable in the **`test_data`** dataset using **`gam_model`**. Store the resulting predictions in a new object called **`predicted_weights_gam`**.\n-   Calculate the mean squared prediction error in the **`test_data`** dataset by comparing the predicted 'weight' values with the actual `weight` values. Store the resulting value in an object called **`MSPE_gam`**.\n\nPrint the value of **`MSPE_gam`** to the console using the **`print()`** function.\n:::\n\n## Your code for Task 4\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Please provide your code for Task 4 in this code chunk\n\nlibrary(mgcv)\n\n# Fit GAM model\ngam_model <- gam(weight ~ s(fage) + s(mage) + s(weeks) + s(visits) + \n                  s(gained) + marital + gender + habit + whitemom, \n                data = train_data,\n                method = \"REML\")\n\n# Print smoothing parameters\nprint(summary(gam_model)$s.table)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n               edf   Ref.df            F     p-value\ns(fage)   1.001200 1.002396   2.08619167 0.148759470\ns(mage)   1.000388 1.000774   0.07901458 0.779096353\ns(weeks)  5.082104 6.147774 129.50469918 0.000000000\ns(visits) 3.119598 3.963131   1.66230248 0.132546087\ns(gained) 1.000384 1.000768   6.82021548 0.009196795\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Make predictions on test set\npredicted_weights_gam <- predict(gam_model, newdata = test_data)\n\n# Calculate MSPE \nMSPE_gam <- mean((test_data$weight - predicted_weights_gam)^2)\n\n# Print MSPE\nprint(MSPE_gam)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1.16755\n```\n:::\n:::\n\n\nMSPE_gam = 1.16755, reflects lower error and improved predictions in the GAM model, attributed to the incorporation of non-linear smoothing functions for continuous predictors.\n\n## TASK 5:\n\n::: {.callout-important appearance=\"simple\"}\n## Task 5\n\n-   Evaluate the effectiveness of the linear regression model (**`linearmodel`**) and the generalized additive model (**`gam_model`**) by comparing their Mean Squared Prediction Errors (MSPE). Utilize the values **`MSPE_linear`** and **`MSPE_gam`**, which were derived in previous tasks, to assess which model more accurately predicts the 'weight' variable in the **`test_data`** dataset. The model with the lower MSPE value will be considered as having superior predictive performance for this specific variable.\n-   **Insert your written response in here:**\n:::\n\n## Your code for Task 5\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Linear Regression MSPE: MSPE_linear = 1.260889\n\n# GAM Model MSPE: MSPE_gam = 1.16755\n```\n:::\n\n\nLinear Regression MSPE: 1.260889\n\nGAM Model MSPE: 1.16755\n\nA lower MSPE signifies enhanced predictive accuracy for the 'weight' variable in the test dataset. In this comparison:\n\n-   If MSPE_linear \\< MSPE_gam: Linear regression outperforms in predictive performance.\n\n-   If MSPE_gam \\< MSPE_linear: The generalized additive model excels in predictive performance.\n\n-   If MSPE_linear ≈ MSPE_gam: Both models perform similarly in predicting the 'weight' variable.\n\nAnalysis reveals the GAM model's superiority with a lower MSPE of 1.117023, indicating reduced deviation between actual and predicted values.\n",
    "supporting": [
      "Ghimire_Ramesh_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}